{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from random import seed, randint\n",
        "import logging\n",
        "from collections import Counter\n",
        "\n",
        "from hw4_util import Tile\n",
        "\n",
        "from hw4_util import read_world\n",
        "from yamada_world import yamada , deer, catalan, churchland, meister, depue, liu, sarkissian, suddath, spell\n",
        "\n",
        "def setup_logging(level):\n",
        "    logging.basicConfig(level=0, format='%(asctime)s{%(levelname)s} %(message)s', datefmt='%H:%M:%S')\n",
        "\n",
        "# shorthand convenience methods for using logger\n",
        "global debug, warn, info, error, crash\n",
        "debug = logging.debug\n",
        "info = logging.info\n",
        "warn = logging.warning\n",
        "error = logging.error\n",
        "crash = logging.critical\n",
        "\n",
        "# initialize logger\n",
        "# debug and warn messages will be skipped\n",
        "setup_logging(logging.WARNING)\n",
        "\n",
        "# the first definition is the last cardinal direction that the agent moved, this is where the agent is \"facing\"\n",
        "# the second dictionary defines what this means for the relative actions of the agent,\n",
        "# for example, if you're facing down and take a right, that's going left in world directions\n",
        "movement_decrypt = {\n",
        "    \"right\": {\"right\": \"down\", \"left\": \"up\", \"forward\": \"right\", \"back\": \"left\"},\n",
        "    \"left\": {\"right\": \"up\", \"left\": \"down\", \"forward\": \"left\", \"back\": \"right\"},\n",
        "    \"up\": {\"right\": \"right\", \"left\": \"left\", \"forward\": \"up\", \"back\": \"down\"},\n",
        "    \"down\": {\"right\": \"left\", \"left\": \"right\", \"forward\": \"down\", \"back\": \"up\"}\n",
        "}\n",
        "\n",
        "# this converts cardinal movements to vectors\n",
        "string_movement_to_vector = {\n",
        "    \"right\": [0, 1],\n",
        "    \"left\": [0, -1],\n",
        "    \"up\": [-1, 0],\n",
        "    \"down\": [1, 0],\n",
        "    \"suck\": [-99, -99]  # should throw error\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(ABC):\n",
        "    '''\n",
        "    An abstract class that represents a roomba Agent for the Vacuum Environments.\n",
        "    ...\n",
        "    Attributes\n",
        "    ----------\n",
        "    percepts : list\n",
        "        A list of strings that represent all of the percepts the agent has had. The last two percepts are the current\n",
        "        percepts of the agent.\n",
        "    performance : integer\n",
        "        An integer representing the number of times the agent has completed a task.\n",
        "    action : string\n",
        "        A string representing the current action the agent is going to take.\n",
        "    Methods\n",
        "    -------\n",
        "    set_percepts(agent_percepts)\n",
        "        sets the agent's perception of the environment as the class variable 'percepts'\n",
        "    rules()\n",
        "        An abstract method used by the subclasses to define the rules of the agent.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, percepts=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        percepts : list\n",
        "            A string list of the history of perceptions from the agent from the environment. The last strings on the\n",
        "            list are the current percepts of the agent.\n",
        "        '''\n",
        "        self.percepts = percepts\n",
        "        self.performance = 0\n",
        "        self.action = \"right\"\n",
        "        self.random_chance = 10\n",
        "\n",
        "    def set_percepts(self, agent_percepts):\n",
        "        '''\n",
        "        Sets the percepts class variable of the environment.\n",
        "        Parameters\n",
        "        ----------\n",
        "        percepts : list\n",
        "            A list of strings that represents the history of perceptions from the Agent's perspective of the environment\n",
        "        '''\n",
        "        self.percepts = agent_percepts\n",
        "\n",
        "    @abstractmethod\n",
        "    def rules(self):\n",
        "        '''\n",
        "        An abstract method used by the subclasses to define the rules of the agent.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "\n",
        "class Toyota_Corolla_Agent(Agent):\n",
        "    '''\n",
        "    A class that represents our first Reflex Agent in the Environment.\n",
        "    ...\n",
        "    Attributes\n",
        "    ----------\n",
        "    percepts : list\n",
        "        A list of strings that represent all of the percepts the agent has had. The last two percepts are the current\n",
        "        percepts of the agent.\n",
        "    performance : integer\n",
        "        An integer representing the number of times the agent has completed a task.\n",
        "    action : string\n",
        "        A string representing the current action the agent is going to take.\n",
        "    Methods\n",
        "    -------\n",
        "    agent_type()\n",
        "        returns agent name, used for agent movement types\n",
        "    rules()\n",
        "        returns an action based on the perception of the environment from the perspective of the agent.\n",
        "    '''\n",
        "\n",
        "    def agent_type(self):\n",
        "        '''\n",
        "        Returns the type of agent.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        agent_type : str\n",
        "            A string representing the type of agent:\n",
        "        '''\n",
        "\n",
        "        return \"Reflex_Agent\"\n",
        "\n",
        "    def rules(self):\n",
        "        '''\n",
        "        Returns an action depending on the agent's perceptions of the environment.\n",
        "        How our rules work is such:\n",
        "        We're always sticking to the right, so the first thing we ALWAYS do is try to move right.\n",
        "        If we tried to move right last action, and we got back a bump in our percept, let's try to move Forward, etc.\n",
        "        Right -> Forward -> Left -> Back\n",
        "\n",
        "        All the agent knows how to do is see if it bumped, then it chooses a new movement,\n",
        "        or it isn't bumped, so it moves right\n",
        "\n",
        "        Remember, these are relative movements, the roomba doesn't know which way is up or down.\n",
        "        The enviornment knows which way the Roomba is pointing however.\n",
        "        The way the roomba is pointing and it's action is decryrpted by the enviornment.\n",
        "        This allows us to stick to the right, even when we're facing left, down, up, or right.\n",
        "        We always move to the relative right.\n",
        "\n",
        "        Raise\n",
        "        -----\n",
        "        raise AttrtibuteError\n",
        "            If self.action is equal to 'error', raise this error to notify that the agent is in a hole.\n",
        "        Returns\n",
        "        -------\n",
        "        action : str\n",
        "            a string representing the action the Agent wants to make in the environment.\n",
        "        '''\n",
        "\n",
        "        rules_dict = {\n",
        "            # this is the sequential order of moves in relative roomba space. directions are relative to where roomba is\n",
        "            # looking, not cardinal environment directions\n",
        "            \"right\": \"forward\",\n",
        "            \"forward\": \"left\",\n",
        "            \"left\": \"back\",\n",
        "            \"back\": \"error\"\n",
        "        }\n",
        "\n",
        "        reverse_dict = {\n",
        "            # this makes the roomba turn around\n",
        "            # turning around means the roomba's old left is not its right, meaning it will try to stick to a wall that's across from it\n",
        "            \"right\": \"left\",\n",
        "            \"forward\": \"back\",\n",
        "            \"left\": \"right\",\n",
        "            \"back\": \"forward\",\n",
        "            \"suck\": \"right\"\n",
        "        }\n",
        "\n",
        "        dirt_percept = self.percepts[-2] # The second to last percept is the current dirt percept\n",
        "        bump_percept = self.percepts[-1] # The last percept is the current bump percept\n",
        "        print(\"-     Agent's POV     -\")\n",
        "        print(f\"Dirt Percept: {dirt_percept}\")\n",
        "        print(f\"Bump Percept: {bump_percept}\")\n",
        "        print(f\"Last Action: {self.action}\")\n",
        "\n",
        "        if dirt_percept == \"dirty\" and not bump_percept == \"bump\":  # if dirty\n",
        "            print(\"IM SUCKING SUCKING SUCKING SUCKING \")\n",
        "            self.action = \"suck\" # suck\n",
        "            self.performance += 1 # update your personal score\n",
        "        else:\n",
        "            if bump_percept == \"bump\":  # okay, we tried to move and we hit something, let's take our last action and use it to find a new one\n",
        "                self.action = rules_dict.get(self.action)\n",
        "                print(\"We Bumped - DICTIONARY ACTION\")\n",
        "                print(self.action)\n",
        "            else:  # we haven't bumped into anything, so try to move right\n",
        "                print(\"Not Bumped - NORMAL ACTION\")\n",
        "                if randint(0, 100) < 5 : # random case to help us get to harder-to-reach areas\n",
        "                    self.action = reverse_dict.get(self.action) # turn around and try to attach to a inside/outside wall\n",
        "                else:\n",
        "                    self.action = \"right\"\n",
        "\n",
        "                print(self.action)\n",
        "\n",
        "            if self.action == \"error\":  # we've tried to move everywhere and nothing worked, throw error\n",
        "                raise AttributeError(\"Roomba is stuck in a hole, no possible movements\")\n",
        "\n",
        "        return self.action\n",
        "\n",
        "class Toyota_Corolla_Agent_Plus(Agent):\n",
        "    '''\n",
        "    A class that represents our first Reflex Agent in the Environment.\n",
        "    ...\n",
        "    Attributes\n",
        "    ----------\n",
        "    percepts : list\n",
        "        tells whether the agent has bumped into a wall, whether the ground/wall is clean\n",
        "    Methods\n",
        "    -------\n",
        "    agent_type()\n",
        "        returns agent name, used for agent movement types\n",
        "    rules()\n",
        "        returns an action based on the perception of the environment from the perspective of the agent.\n",
        "    '''\n",
        "\n",
        "    def agent_type(self):\n",
        "        '''\n",
        "        Returns the type of agent.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            A string representing the type of agent.\n",
        "        '''\n",
        "\n",
        "        return \"Reflex_Agent\"\n",
        "\n",
        "    def rules(self):\n",
        "        '''\n",
        "        Returns an action depending on the agent's perceptions of the environment.\n",
        "        How our rules work is such:\n",
        "        We're always sticking to the right, so the first thing we ALWAYS do is try to move right.\n",
        "        If we tried to move right last action, and we got back a bump in our percept, let's try to move Forward, etc.\n",
        "        Right -> Forward -> Left -> Back\n",
        "\n",
        "        All the agent knows how to do is see if it bumped, then it chooses a new movement,\n",
        "                                        or it isn't bumped, so it moves right\n",
        "\n",
        "        Remember, these are relative movements, the roomba doesn't know which way is up or down.\n",
        "        The enviornment knows which way the Roomba is pointing however.\n",
        "        The way the roomba is pointing and it's action is decryrpted by the enviornment.\n",
        "        This allows us to stick to the right, even when we're facing left, down, up, or right.\n",
        "        We always move to the relative right.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action : str\n",
        "            a string representing the action the Agent wants to make in the environment.\n",
        "        '''\n",
        "\n",
        "        rules_dict = {\n",
        "            # this is the sequential order of moves in relative roomba space. directions are relative to where roomba is\n",
        "            # looking, not cardinal environment directions\n",
        "            \"right\": \"forward\",\n",
        "            \"forward\": \"left\",\n",
        "            \"left\": \"back\",\n",
        "            \"back\": \"error\",\n",
        "            \"hose\": \"right\"\n",
        "        }\n",
        "\n",
        "        reverse_dict = {\n",
        "            # this makes the roomba turn around\n",
        "            # turning around means the roomba's old left is not its right, \n",
        "            # meaning it will try to stick to a wall that's across from it \n",
        "            \"right\": \"left\",\n",
        "            \"forward\": \"back\",\n",
        "            \"left\": \"right\",\n",
        "            \"back\": \"forward\",\n",
        "            \"suck\": \"right\",\n",
        "            \"hose\": \"right\"\n",
        "        }\n",
        "\n",
        "        dirt_percept = self.percepts[-2]\n",
        "        bump_percept = self.percepts[-1]\n",
        "        print(\"-     Agent's POV     -\")\n",
        "        print(f\"Dirt Percept: {dirt_percept}\")\n",
        "        print(f\"Bump Percept: {bump_percept}\")\n",
        "        print(f\"Last Action: {self.action}\")\n",
        "\n",
        "        if dirt_percept == \"dirty\":  # if dirty\n",
        "            if bump_percept == \"bump\":\n",
        "                print(\"IM HOSING HOSING HOSING HOSING \")\n",
        "                self.action = \"hose\"  # suck\n",
        "                self.performance += 1  # update your personal score\n",
        "            else:\n",
        "                print(\"IM SUCKING SUCKING SUCKING SUCKING \")\n",
        "                self.action = \"suck\" # suck\n",
        "                self.performance += 1 # update your personal score\n",
        "        else:\n",
        "            if bump_percept == \"bump\":  # okay, we tried to move and we hit something, let's take our last action and use it to find a new one\n",
        "                self.action = rules_dict.get(self.action)\n",
        "                print(\"We Bumped - DICTIONARY ACTION\")\n",
        "                print(self.action)\n",
        "            else:  # we haven't bumped into anything, so try to move right\n",
        "                print(\"Not Bumped - NORMAL ACTION\")\n",
        "                if randint(0, 100) < 5 : # random case to help us get to harder-to-reach areas\n",
        "                    # self.action = \"right\"\n",
        "                    self.action = reverse_dict.get(self.action) # turn around and try to attach to a inside/outside wall\n",
        "                else:\n",
        "                    self.action = \"right\"\n",
        "\n",
        "                print(self.action)\n",
        "\n",
        "            if self.action == \"error\":  # we've tried to move everywhere and nothing worked, throw error\n",
        "                raise AttributeError(\"Roomba is stuck in a hole, no possible movements\")\n",
        "\n",
        "        return self.action\n",
        "\n",
        "class Simple_Agent(Agent):\n",
        "    '''\n",
        "    A class that represents our second Reflex Agent in the Environment.\n",
        "    We were scared that our first reflex agent was using too much information about the environment\n",
        "    ...\n",
        "    Attributes\n",
        "    ----------\n",
        "    percepts : list\n",
        "        tells whether the agent has bumped into a wall and whether the ground/wall is clean\n",
        "    Methods\n",
        "    -------\n",
        "    agent_type()\n",
        "        returns agent name, used for agent movement types\n",
        "    rules()\n",
        "        returns an action based on the perception of the environment from the perspective of the agent.\n",
        "    '''\n",
        "\n",
        "    def agent_type(self):\n",
        "        '''\n",
        "        Returns the type of agent.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            A string representing the type of agent.\n",
        "        '''\n",
        "\n",
        "        return \"Simple_Agent\"\n",
        "\n",
        "    def rules(self):\n",
        "        '''\n",
        "        Returns an action depending on the agent's perceptions of the environment.\n",
        "        How our rules work is such:\n",
        "        This is the simple agent, in case Spell doesn't like what we're doing with our Reflex Agent\n",
        "        All it does is always turn left if bumped, forward if not.\n",
        "        I threw some randomness in there to help it out.\n",
        "        There's no action sequence here, unlike the other bot.\n",
        "        This one can get stuck much easier.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action : str\n",
        "            a string representing the action the Agent wants to make in the environment.\n",
        "        '''\n",
        "\n",
        "        dirt_percept = self.percepts[-2]\n",
        "        bump_percept = self.percepts[-1]\n",
        "        print(\"-     Agent's POV     -\")\n",
        "        print(f\"Dirt Percept: {dirt_percept}\")\n",
        "        print(f\"Bump Percept: {bump_percept}\")\n",
        "        print(f\"Last Action: {self.action}\")\n",
        "\n",
        "        if dirt_percept == \"dirty\":  # if dirty\n",
        "            if bump_percept == \"bump\":\n",
        "                print(\"IM HOSING HOSING HOSING HOSING \")\n",
        "                self.action = \"hose\"  # suck\n",
        "                self.performance += 1  # update your personal score\n",
        "            print(\"IM SUCKING SUCKING SUCKING SUCKING \")\n",
        "            self.action = \"suck\"  # suck\n",
        "            self.performance += 1  # update your personal score\n",
        "        else:\n",
        "            if bump_percept == \"bump\":  # okay, we tried to move and we hit something, let's take our last action and use it to find a new one\n",
        "                if randint(0, 100) < 5:\n",
        "                    self.action = \"right\"\n",
        "                else:\n",
        "                    self.action = \"left\"\n",
        "            else:\n",
        "                self.action = \"forward\"\n",
        "\n",
        "        return self.action\n",
        "\n",
        "class Defect_Agent(Agent):\n",
        "    '''\n",
        "    A class that represents our defective agent.\n",
        "    Since you said that it has a 25% of leaking dirt, all we're doing is staying in the same place and sucking.\n",
        "    This will mean we're optimizing our performance by abusing our faults.\n",
        "\n",
        "    This is a kind of exploit, more because our Toyota Corolla works great even with defects.\n",
        "    If you don't like how we're maximizing our utiliity here, you can just use the toyota corolla with the defect env.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    percepts : list\n",
        "        tells whether the agent has bumped into a wall, whether the ground/wall is clean\n",
        "    Methods\n",
        "    -------\n",
        "    agent_type()\n",
        "        returns agent name, used for agent movement types\n",
        "    rules()\n",
        "        always returns \"suck\" to maximize performance\n",
        "    '''\n",
        "\n",
        "    def agent_type(self):\n",
        "        '''\n",
        "        Returns the type of agent.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            A string representing the type of agent.\n",
        "        '''\n",
        "\n",
        "        return \"Simple_Agent\"\n",
        "\n",
        "    def rules(self):\n",
        "        '''\n",
        "        Returns an action depending on the agent's perceptions of the environment.\n",
        "        How our rules work is such:\n",
        "        This is the simple agent, in case Spell doesn't like what we're doing with our Reflex Agent\n",
        "        All it does is always turn left if bumped, forward if not.\n",
        "        I threw some randomness in there to help it out.\n",
        "        There's no action sequence here, unlike the other bot.\n",
        "        This one can get stuck much easier.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action : str\n",
        "            a string representing the action the Agent wants to make in the environment.\n",
        "        '''\n",
        "\n",
        "        dirt_percept = self.percepts[-2]\n",
        "        bump_percept = self.percepts[-1]\n",
        "        print(\"-     Agent's POV     -\")\n",
        "        print(f\"Dirt Percept: {dirt_percept}\")\n",
        "        print(f\"Bump Percept: {bump_percept}\")\n",
        "        print(f\"Last Action: {self.action}\")\n",
        "\n",
        "        if dirt_percept == \"dirty\":  # if dirty\n",
        "            print(\"IM SUCKING SUCKING SUCKING SUCKING \")\n",
        "            self.action = \"suck\"  # suck\n",
        "            self.performance += 1  # update your personal score\n",
        "        else:\n",
        "            print(\"IM LEAKING INTENTIONALLY\")\n",
        "            self.action = \"suck\"  # suck\n",
        "\n",
        "        return self.action\n",
        "\n",
        "class Model_Agent(Agent):\n",
        "    '''\n",
        "    A class that represents an Agent in the Environment.\n",
        "    ...\n",
        "    Attributes\n",
        "    ----------\n",
        "    percepts : list\n",
        "        tells whether the agent has bumped into a wall, whether the ground/wall is clean\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    agent_type()\n",
        "        returns agent name, used for agent movement types\n",
        "    prepmap()\n",
        "        Prepares the list that will contain the map for mapping to begin.\n",
        "    interpret_cardinal_action\n",
        "        Converts the relative actions that the agent outputs into cardinal actions for the mapping function\n",
        "    mapping()\n",
        "        tries to construct a roomba based understanding of the environment\n",
        "    virtual bump check()\n",
        "        checks if agent will virtually bump into a virtual wall\n",
        "    virtual_rules()\n",
        "        runs the rules function recursively to find rules that apply to virtual worlds\n",
        "    get_pos_value()\n",
        "        Checks the value of a given square in the world (relative to starting position)\n",
        "    has_visited()\n",
        "        Checks whether the agent has visited a certain square\n",
        "    loop_tracker()\n",
        "        Watches for possible loops the agent could be stuck in\n",
        "    rules()\n",
        "        returns an action based on the perception of the environment from the perspective of the agent.\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.world=[]\n",
        "        self.agent_col=0\n",
        "        self.agent_row=0\n",
        "        self.prepmap(6, 7)\n",
        "        self.agent_last_successful = \"right\"\n",
        "        self.cardinal_action = \"right\"\n",
        "        self.antiloop = []  # list to be used to monitor whether the agent is stuck in a loop\n",
        "        super().__init__()\n",
        "\n",
        "    def agent_type(self):\n",
        "        '''\n",
        "        Returns the type of agent.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            A string representing the type of agent.\n",
        "        '''\n",
        "\n",
        "        return \"Model_Agent\"\n",
        "\n",
        "    def prepmap(self, x, y):\n",
        "        '''\n",
        "        Prepares the list that will contain the map for mapping to begin.\n",
        "        Relies on the starting dimensions of the world to make a filler list\n",
        "        that will be guaranteed to contain the world no matter where the agent starts.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : int\n",
        "            The x starting position of the agent in the agent's representation of the world.\n",
        "        y : int\n",
        "            The y starting position of the agent in the agent's representation of the world.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self.world : nested list\n",
        "            Nested list of '-' with dimensions sufficient to contain the environment.\n",
        "        '''\n",
        "\n",
        "        row = list('-' * ((2 * x) - 1))\n",
        "        for i in range(((2 * y) - 1)):\n",
        "            self.world.append(row[:])\n",
        "        self.agent_col = x - 1\n",
        "        self.agent_row = y - 1\n",
        "        return self.world\n",
        "\n",
        "    def interpret_cardinal_action(self):\n",
        "        '''\n",
        "        Converts the relative actions that the agent outputs into cardinal actions for the mapping function\n",
        "        '''\n",
        "\n",
        "        if self.action != \"suck\":\n",
        "            self.cardinal_action = str(movement_decrypt[self.agent_last_successful][self.action])\n",
        "\n",
        "    def mapping(self, agent_percepts):\n",
        "        '''\n",
        "        Agent constructs a map of the world based on past experience\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent_percepts : list\n",
        "            A list of strings that represents the history of perceptions from the Agent's perspective of the environment\n",
        "        '''\n",
        "\n",
        "        if self.cardinal_action == \"right\":  # agent moves right\n",
        "            if str(agent_percepts[1]) == \"clean\" or str(agent_percepts[1]) == \"dirty\":  # agent has not ran into a wall\n",
        "                self.agent_col += 1  # collumn variable changed\n",
        "                self.world[self.agent_row][self.agent_col] = 1  # agent's new square marked as empty\n",
        "            else:  # agent has ran into wall\n",
        "                self.world[self.agent_row][self.agent_col + 1] = 2  # square to the right of the agent marked as wall\n",
        "        if self.cardinal_action == \"left\":  # agent moves left\n",
        "            if str(agent_percepts[1]) == \"clean\" or str(agent_percepts[1]) == \"dirty\":  # agent has not ran into wall\n",
        "                self.agent_col -= 1  # collumn variable changed appropriately\n",
        "                self.world[self.agent_row][self.agent_col] = 1  # agent's new position marked as empty\n",
        "            else:  # agent has hit a wall\n",
        "                self.world[self.agent_row][self.agent_col - 1] = 2  # square to the left of agent marked as wall\n",
        "        if self.cardinal_action == \"up\":  # agent moves up\n",
        "            if str(agent_percepts[1]) == \"clean\" or str(agent_percepts[1]) == \"dirty\":  # agent has not hit a wall\n",
        "                self.agent_row -= 1  # row variable decreased\n",
        "                self.world[self.agent_row][self.agent_col] = 1  # agent's new position marked as empty\n",
        "            else:  # agent has encountered a wall\n",
        "                self.world[self.agent_row - 1][self.agent_col] = 2  # square directly above agent marked as wall\n",
        "        if self.cardinal_action == \"down\":  # agent moves down\n",
        "            if str(agent_percepts[1]) == \"clean\" or str(agent_percepts[1]) == \"dirty\":  # agent does not hit wall\n",
        "                self.agent_row += 1\n",
        "                self.world[self.agent_row][self.agent_col] = 1\n",
        "            else:  # agent has encountered wall\n",
        "                self.world[self.agent_row + 1][self.agent_col] = 2  # square directly below agent marked as wall\n",
        "\n",
        "    def get_pos_value(self, x, y):\n",
        "        '''\n",
        "        This checks the value of a given square in the world (relative to starting position)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : int\n",
        "            The x position of where you want to check.\n",
        "        y : int\n",
        "            The y position of where you want to check.\n",
        "        '''\n",
        "\n",
        "        return self.world[x][y]\n",
        "\n",
        "    def has_visited(self, x, y):\n",
        "        '''\n",
        "        Checks whether the agent has visited a certain square\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : int\n",
        "            The x position of where you want to check.\n",
        "        y : int\n",
        "            The y position of where you want to check.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bool\n",
        "            Returns true if the agent hasn't visited the position\n",
        "        '''\n",
        "\n",
        "        if self.world[x][y] != '-':\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def loop_tracker(self):\n",
        "        '''\n",
        "        Watches for possible loops the agent could be stuck in a hole.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bool\n",
        "            Returns true if it is stuck\n",
        "        '''\n",
        "\n",
        "        coords = [self.agent_row, self.agent_col]  # coordinates of agent\n",
        "        if self.has_visited(coords[0], coords[1]):\n",
        "            if self.antiloop.count([coords]) >= 3:  # method of tracking loops only works if agent has visited a square at least 3 times\n",
        "                loop_spots = [i for i in range(len(self.antiloop)) if self.antiloop[i] == [coords]][-3:-1]  # makes list of indexes of every time the agent has previously been in its current square (only takes the last 2 as only 2 are needed)\n",
        "                if self.antiloop[loop_spots[0] + 1] == self.antiloop[loop_spots[1] + 1]:  # if the move directly after each of the previous visits is the same then the agent might be stuck in a loop\n",
        "                    self.antiloop = []  # list keeping track of previous positions is wiped so the previous if/else statements don't keep checking the same occurences\n",
        "                    return True\n",
        "                else:\n",
        "                    self.antiloop = []  # list keeping track is wiped for the same reason\n",
        "                    self.antiloop.append([coords])  # current coordinates are appended\n",
        "                    return False\n",
        "            else:\n",
        "                self.antiloop.append([coords])  # if agent has not visited a given square at least 3 times its current position is added to list\n",
        "\n",
        "    def rules(self):\n",
        "        '''\n",
        "        Returns an action depending on the agent's perceptions of the environment.\n",
        "        How our rules work is such:\n",
        "        We're always sticking to the right, so the first thing we ALWAYS do is try to move right.\n",
        "        If we tried to move right last action, and we got back a bump in our percept, let's try to move Forward, etc.\n",
        "        Right -> Forward -> Left -> Back\n",
        "        But this agent is MUCH SMARTER than the last one because we now can maintain state of the world.\n",
        "        What we're doing now is trying to spiral around the world until we reach the inside.\n",
        "        In order to spiral inwards, we need to pretend like there's blocks in certain spaces : \"Virtual Walls\"\n",
        "        These Virtual Walls should impede our movement, but they don't exist in the environment, the enviornment has no\n",
        "        idea about them\n",
        "\n",
        "        What we're doing here is doing our normal movement code, then checking if that movement will cause a bump into\n",
        "        our Virtual Walls.\n",
        "\n",
        "        If that movement will make us go into a virtual wall, we send it back to regenerate, making the rules think we\n",
        "        just bumped into something and it's the next step, but it isn't\n",
        "        This creates the recursive nature of our virtual code.\n",
        "        Remember, these are relative movements, the roomba doesn't know which way is up or down.\n",
        "        The enviornment knows which way the Roomba is pointing however. The way the roomba is pointing and it's action\n",
        "        is decryrpted by the enviornment.\n",
        "\n",
        "        This allows us to stick to the right, even when we're facing left, down, up, or right. We always move to the\n",
        "        relative right.\n",
        "        Returns\n",
        "        -------\n",
        "        action : str\n",
        "            a string representing the action the Agent wants to make in the environment.\n",
        "        '''\n",
        "\n",
        "        rules_dict = {\n",
        "            # this is the sequential order of moves in relative roomba space. directions are relative to where roomba is\n",
        "            # looking, not cardinal environment directions\n",
        "            \"right\": \"forward\",\n",
        "            \"forward\": \"left\",\n",
        "            \"left\": \"back\",\n",
        "            \"back\": \"error\"\n",
        "        }\n",
        "\n",
        "        reverse_dict = {\n",
        "            # this makes the roomba turn around\n",
        "            # turning around means the roomba's old left is not its right, meaning it will try to stick to a wall that's across from it\n",
        "            \"right\": \"left\",\n",
        "            \"forward\": \"back\",\n",
        "            \"left\": \"right\",\n",
        "            \"back\": \"forward\",\n",
        "            \"suck\": \"right\"\n",
        "        }\n",
        "\n",
        "        dirt_percept = self.percepts[-2] # The second to last percept is the current dirt percept\n",
        "        bump_percept = self.percepts[-1] # The last percept is the current bump percept\n",
        "        print(\"-     Agent's POV     -\")\n",
        "        print(f\"Dirt Percept: {dirt_percept}\")\n",
        "        print(f\"Bump Percept: {bump_percept}\")\n",
        "        print(f\"Last Action: {self.action}\")\n",
        "\n",
        "        if dirt_percept == \"dirty\" and not bump_percept == \"bump\":  # if dirty\n",
        "            print(\"IM SUCKING SUCKING SUCKING SUCKING \")\n",
        "            self.action = \"suck\" # suck\n",
        "            self.performance += 1 # update your personal score\n",
        "        else:\n",
        "            if bump_percept == \"bump\":  # okay, we tried to move and we hit something, let's take our last action and use it to find a new one\n",
        "                self.action = rules_dict.get(self.action)\n",
        "                print(\"We Bumped - DICTIONARY ACTION\")\n",
        "                print(self.action)\n",
        "            else:  # we haven't bumped into anything, so try to move right\n",
        "                print(\"Not Bumped - NORMAL ACTION\")\n",
        "                if self.loop_tracker(): # random case to help us get to harder-to-reach areas\n",
        "                    self.action = reverse_dict.get(self.action) # turn around and try to attach to a inside/outside wall\n",
        "                else:\n",
        "                    self.action = \"right\"\n",
        "\n",
        "                print(self.action)\n",
        "\n",
        "            if self.action == \"error\":  # we've tried to move everywhere and nothing worked, throw error\n",
        "                raise AttributeError(\"Roomba is stuck in a hole, no possible movements\")\n",
        "\n",
        "        return self.action"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vacuum_Environment(ABC):\n",
        "    \"\"\"\n",
        "    An abstract class representing a room with nothing (0), clean (1), wall (2), dirty (3)\n",
        "    ...\n",
        "    Attributes\n",
        "    ----------\n",
        "    world : nested list\n",
        "        a nested integer list representing the rooms within the vacuum environment as nothing (0), clean (1), wall (2),\n",
        "        and dirty (3).\n",
        "    agent_action : str\n",
        "        the action the agent will do in the environment based in cardinal direction.\n",
        "    agent_last_movement : str\n",
        "        the last succesful action the agent took in the enviornemnt in cardinal direction.\n",
        "    agent_action_relative : str\n",
        "        the action the agent took in the enviornment in relative orientation.\n",
        "    environment_won : bool\n",
        "        Keeps track of whether the environment it is currently in is already won.\n",
        "    score : int\n",
        "        Keeps track of the number of times the agent has completed the environments' tasks.\n",
        "    agent_percepts_history : list\n",
        "        A list of strings that represents the history of perceptions from the Agent's perspective of the environment.\n",
        "    agent_percepts_buffer : list\n",
        "        A list of strings that represents the current perceptions of the environment.\n",
        "    agent_position : list\n",
        "        The position of the agent in [row, collumn]\n",
        "    bump : bool\n",
        "        Used to communicate cross function in 'bump_percept' to 'change_environment' whether agent has bumped.\n",
        "    clean_indexes : list\n",
        "        The indexes of clean rooms in the 2D environment.\n",
        "    defective : bool\n",
        "        Whether the roomba is defective and has a 25% chance to leak dirt.\n",
        "    leak_dirt : bool\n",
        "        When defective is true, leak_dirt has a 25% chance to be true and cause the next or current clean room dirty.\n",
        "    hose_percept : bool\n",
        "        Whether to include a percept for dirty walls.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    create_world()\n",
        "        Sets the 'world' class variable representing the different rooms in the environment.\n",
        "    create_dirt(number_of_dirt)\n",
        "        Creates number_of_dirt many dirty rooms in random clean rooms in the environment.\n",
        "    do_kids_create_dirt()\n",
        "        Randomly creates dirt in a clean room according to the 10% kids creating dirt chance.\n",
        "    agent_percept()\n",
        "        Runs all the agent percept functions and resets the buffer after checking it.\n",
        "    agent_dirt_sensor()\n",
        "        Adds and sets that inside of the agent. Then, it calls agent.rules() to get the\n",
        "        agent's action and sets that equal to the 'agent_action' class variable.\n",
        "    agent_bump_sensor()\n",
        "        Makes the object agent's percepts and sets that inside of the agent. Then, it calls agent.rules() to get the\n",
        "        agent's action and sets that equal to the 'agent_action' class variable.\n",
        "    agent_program(agent)\n",
        "        Makes the object agent's percepts and sets that inside of the agent. Then, it calls agent.rules() to get the\n",
        "        agent's action and sets that equal to the 'agent_action' class variable.\n",
        "    change_environment()\n",
        "        Changes the state of the environment based on the agent_action class variable.\n",
        "    update_agent_position()\n",
        "        Sets agent's position.\n",
        "    get_dirt_status()\n",
        "        Getter for the status of the number of dirty rooms in the room environment.\n",
        "    __repr__()\n",
        "        Represents the class when printed as a formatted string of the 'world' class variable with the agent's position\n",
        "        in the room environment represented by a asterisks (*)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        world : nested list\n",
        "            a nested integer list representing the rooms within the vacuum environment as nothing (0), clean (1), wall (2),\n",
        "            and dirty (3).\n",
        "        agent_action : str\n",
        "            the action the agent will do in the environment based in cardinal direction.\n",
        "        agent_last_movement : str\n",
        "            the last succesful action the agent took in the enviornemnt in cardinal direction.\n",
        "        agent_action_relative : str\n",
        "            the action the agent took in the enviornment in relative orientation.\n",
        "        environment_won : bool\n",
        "            Keeps track of whether the environment it is currently in is already won.\n",
        "        score : int\n",
        "            Keeps track of the number of times the agent has completed the environments' tasks.\n",
        "        agent_percepts_history : list\n",
        "            A list of strings that represents the history of perceptions from the Agent's perspective of the environment.\n",
        "        agent_percepts_buffer : list\n",
        "            A list of strings that represents the current perceptions of the environment.\n",
        "        agent_position : list\n",
        "            The position of the agent in [row, collumn]\n",
        "        bump : bool\n",
        "            Used to communicate cross function in 'bump_percept' to 'change_environment' whether agent has bumped.\n",
        "        clean_indexes : list\n",
        "            The indexes of clean rooms in the 2D environment.\n",
        "        defective : bool\n",
        "            Whether the roomba is defective and has a 25% chance to leak dirt.\n",
        "        leak_dirt : bool\n",
        "            When defective is true, leak_dirt has a 25% chance to be true and cause the next or current clean room dirty.\n",
        "        hose_percept : bool\n",
        "            Whether to include a percept for dirty walls.\n",
        "        '''\n",
        "\n",
        "        self.world = []\n",
        "        self.agent_action = \"\"\n",
        "        self.agent_last_movement = \"right\"\n",
        "        self.agent_action_relative = \"right\"\n",
        "        self.universal_last_agent_action = \"right\"\n",
        "        self.environment_won = False\n",
        "        self.score = 0\n",
        "        self.agent_percepts_history = []\n",
        "        self.agent_percepts_buffer = []\n",
        "        self.agent_position = []\n",
        "        self.bump = False\n",
        "        self.clean_indexes = []\n",
        "        self.defective = False\n",
        "        self.leak_dirt = False\n",
        "        self.hose_percept = False\n",
        "\n",
        "    def create_world(self, world_parameter):\n",
        "        '''\n",
        "        Sets the 'world' class variable representing the different rooms in the environment.\n",
        "        The 'world' class variable is an integer list representing the environment and the objects within each room:\n",
        "        nothing (0), clean (1), wall (2), dirty (3)\n",
        "        Sets agent to a random spawn location\n",
        "\n",
        "        Asserts\n",
        "        -------\n",
        "            If world_parameter is None, assert.\n",
        "        '''\n",
        "\n",
        "        assert world_parameter is not None, \"Make sure that you have a variable name with your lastname as the configuration \" \\\n",
        "                                   \"of your world\"\n",
        "        self.world = read_world(world_parameter)\n",
        "        self.clean_indexes=[]\n",
        "        for row in range(len(self.world)):\n",
        "            for element in range(row):\n",
        "                if str(self.world[row][element])==\"CLEAN\":\n",
        "                    self.clean_indexes.append([row,element])\n",
        "        self.agent_position=self.clean_indexes[randint(0,len(self.clean_indexes)-1)]\n",
        "        seed(self.world[0][0], 2)  # random seed based on world\n",
        "\n",
        "    def create_dirt(self, number_of_dirt):\n",
        "        '''\n",
        "        Creates number_of_dirt many dirty rooms in random clean rooms in the environment.\n",
        "        Parameters\n",
        "        ----------\n",
        "            number_of_dirt : Number of clean rooms to be converted into dirty rooms\n",
        "\n",
        "        Asserts\n",
        "        -------\n",
        "            number_of_dirt cannot be equal to 0\n",
        "        '''\n",
        "\n",
        "        assert number_of_dirt != 0, \"Cannot make 0 dirt\"\n",
        "\n",
        "        clean_tile_in_world = False\n",
        "        for row in self.world:\n",
        "            for element in row:\n",
        "                if element.value == 1:\n",
        "                    clean_tile_in_world = True\n",
        "\n",
        "        if clean_tile_in_world == False:\n",
        "            return\n",
        "\n",
        "        dirt_created = 0  # Number of clean rooms converted into dirty rooms\n",
        "\n",
        "        while True:\n",
        "            random_row = randint(0, len(self.world)-1) # Random row in the world environment\n",
        "            clean_rooms = 0\n",
        "            for i in self.world[random_row]: # Shorten this was map and lambda\n",
        "                if i.value == 1:\n",
        "                    clean_rooms += 1\n",
        "            if dirt_created == number_of_dirt: # If the desired number of dirty rooms have been created, stop\n",
        "                break\n",
        "            elif clean_rooms > 0: # Else if the number of clean rooms in the row is greater than 0. If not, go to\n",
        "                                  # Another row.\n",
        "                dirty_room = randint(0, clean_rooms-1) # The xth clean room in the row is going to become dirty\n",
        "                clean_room_count = 0 # Number of clean rooms already cycled through\n",
        "                for i in range(len(self.world[random_row])): # Cycle through to the desired row\n",
        "                    if self.world[random_row][i].value == 1:\n",
        "                        if clean_room_count == dirty_room: # If its the desired clean room to be dirty, make it dirty.\n",
        "                            self.world[random_row][i] = dirty_tile\n",
        "                            dirt_created += 1\n",
        "                            break\n",
        "                        else:\n",
        "                            clean_room_count += 1\n",
        "\n",
        "    def do_kids_create_dirt(self):\n",
        "        '''\n",
        "        Randomly creates dirt in a clean room according to the 10% kids creating dirt chance.\n",
        "        '''\n",
        "\n",
        "        if randint(0, 10) == 5:\n",
        "            self.create_dirt(1)\n",
        "\n",
        "    def agent_percept(self, agent):\n",
        "        '''\n",
        "        Runs all the agent percept functions and resets the buffer after checking it.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent : Object of Agent class\n",
        "        '''\n",
        "        self.agent_dirt_sensor(agent)\n",
        "        self.agent_bump_sensor()\n",
        "        agent.set_percepts(self.agent_percepts_buffer)\n",
        "        self.agent_percepts_buffer = []\n",
        "\n",
        "        self.hose_percept = False\n",
        "\n",
        "    def agent_dirt_sensor(self, agent):\n",
        "        '''\n",
        "        Adds and sets that inside of the agent. Then, it calls agent.rules() to get the\n",
        "        agent's action and sets that equal to the 'agent_action' class variable.\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent : Object of Agent class\n",
        "        '''\n",
        "\n",
        "        print(\"-     Dirt Percept      -\")\n",
        "        print(f\"Agent Is In: {self.world[self.agent_position[0]][self.agent_position[1]]}\")\n",
        "        print(f\"Hose Percept Is: {self.hose_percept}\")\n",
        "\n",
        "        if str(self.world[self.agent_position[0]][self.agent_position[1]]) == \"DIRTY\" or self.hose_percept:\n",
        "            print(\"Agent is passed Dirty percept\")\n",
        "            self.agent_percepts_history.append(\"dirty\")\n",
        "            self.agent_percepts_buffer.append(\"dirty\")\n",
        "        else:\n",
        "            print(\"Agent is passed Clean percept\")\n",
        "            self.agent_percepts_history.append(\"clean\")\n",
        "            self.agent_percepts_buffer.append(\"clean\")\n",
        "\n",
        "    def agent_bump_sensor(self):\n",
        "        '''\n",
        "        Sets the agent's bump percept for the 'agent_percepts_history' and 'agent_percepts_buffer' class variables of\n",
        "        the agent.\n",
        "        '''\n",
        "\n",
        "        if self.bump:\n",
        "            self.agent_percepts_history.append(\"bump\")\n",
        "            self.agent_percepts_buffer.append(\"bump\")\n",
        "            self.bump = False\n",
        "        else:\n",
        "            self.agent_percepts_history.append(\"no bump\")\n",
        "            self.agent_percepts_buffer.append(\"no bump\")\n",
        "\n",
        "    def change_environment(self):\n",
        "        '''\n",
        "        Changes the state of the environment based on the agent_action class variable.\n",
        "        If the dirty room becomes clean, the 'dirty_room' class variable becomes an empty list since there are no more\n",
        "        dirty rooms in the environment.\n",
        "        '''\n",
        "\n",
        "        print(\"-     Change Enviornment      -\")\n",
        "        print(f\"Agent Is In: {self.world[self.agent_position[0]][self.agent_position[1]]}\")\n",
        "\n",
        "        if self.leak_dirt and str(self.world[self.agent_position[0]][self.agent_position[1]]) == \"CLEAN\":\n",
        "            self.world[self.agent_position[0]][self.agent_position[1]] = dirty_tile\n",
        "\n",
        "        if self.agent_action == \"suck\":\n",
        "            if str(self.world[self.agent_position[0]][self.agent_position[1]]) == \"DIRTY\" and not self.defective:\n",
        "                print(\"X  X  X  POGGERS WE JUST CLEANED UP  X  X  X \")\n",
        "                self.world[self.agent_position[0]][self.agent_position[1]] = clean_tile\n",
        "                self.score += 1\n",
        "            else:\n",
        "                print(\"ERROR - TRIED TO SUCK IN CLEAN\")\n",
        "                error(\"TRIED TO SUCK IN CLEAN\")\n",
        "        elif self.agent_action == \"hose\":\n",
        "            hose_movement_vector = string_movement_to_vector.get(self.universal_last_agent_action)\n",
        "            print(f\"Hose Movement_vector: {hose_movement_vector}\")\n",
        "            print(f\"Agent_position: {self.agent_position}\")\n",
        "            hose_test_position = [self.agent_position[0] + hose_movement_vector[0], self.agent_position[1] + hose_movement_vector[1]]\n",
        "            if 0 <= hose_test_position[0] < 6 and 0 <= hose_test_position[1] < 7:\n",
        "                if \"DIRTY\" in str(self.world[hose_test_position[0]][hose_test_position[1]]):\n",
        "                    self.world[hose_test_position[0]][hose_test_position[1]] = wall_tile\n",
        "                    self.score += 1\n",
        "                else:\n",
        "                    print(\"ERROR - TRIED TO HOSE CLEAN WALL\")\n",
        "                    error(\"TRIED TO HOSE CLEAN WALL\")\n",
        "        else:\n",
        "            # print(self.agent_action)\n",
        "            movement_vector = string_movement_to_vector.get(self.agent_action)\n",
        "            print(f\"Movement_vector: {movement_vector}\")\n",
        "            print(f\"Agent_position: {self.agent_position}\")\n",
        "            test_position = [self.agent_position[0] + movement_vector[0], self.agent_position[1] + movement_vector[1]]\n",
        "            self.update_agent_position(self.check_bounds(test_position, self.agent_position))\n",
        "\n",
        "    def update_agent_position(self, position):\n",
        "        '''\n",
        "        Sets agent's position\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        position : list\n",
        "            A list containing the y and x values of the agent's position in the vacuum world.\n",
        "        '''\n",
        "\n",
        "        self.agent_position = position\n",
        "\n",
        "    def __repr__(self):\n",
        "        '''\n",
        "        Prints the environment 'world' formatted with nothing as \"OUT\", clean as \"CLEAN\", wall as \"WALL\", and dirty as\n",
        "        \"DIRTY\".\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            an str list with four states: [\"OUT\", \"CLEAN\", \"WALL\",\"DIRTY\"].\n",
        "        '''\n",
        "        world_with_agent = []\n",
        "        row = []\n",
        "        for i in range(len(self.world)):\n",
        "            row = []\n",
        "            for j in range(len(self.world[i])):\n",
        "                element = self.world[i][j]\n",
        "                if i == self.agent_position[0] and j == self.agent_position[1]:\n",
        "                    row.append(f\"Agent + {element}\")\n",
        "                else:\n",
        "                    row.append(element)\n",
        "            world_with_agent.append(row)\n",
        "\n",
        "        # world_with_agent[self.agent_position[0]][self.agent_position[1]] = f\"AGENT_POSITION + {agent_is_in}\"\n",
        "        pretty_world = '\\n'.join(map(str, world_with_agent))\n",
        "        return pretty_world\n",
        "\n",
        "class Normal_Vacuum_Environment(Vacuum_Environment):\n",
        "    \"\"\"\n",
        "    A class representing a vacuum environment for the Model_Agent with nothing (0), clean (1), wall (2), dirty (3)\n",
        "\n",
        "    Different than normal_vaccuum_enviornment in the way that it records agent movement to figure out where the agent\n",
        "    has rotated to, similar to how roombas work, depending on whether it bumps or succeeds.\n",
        "\n",
        "    ...\n",
        "    Methods\n",
        "    -------\n",
        "    agent_update()\n",
        "        Updates the agent and interprets the agent movement.\n",
        "    check_bounds()\n",
        "        Checks whether the Agent movement will result in a Bump or result in movement.\n",
        "    \"\"\"\n",
        "\n",
        "    def agent_update(self, agent):\n",
        "        '''\n",
        "        Updates the agent and interprets the agent movement.\n",
        "        For info on why we're using relative positioning and directions here, see wiki or agent descriptions.\n",
        "\n",
        "        ----------\n",
        "        Parameters\n",
        "            agent : Agent to be updated and taken action from\n",
        "        ----------\n",
        "        Variables\n",
        "            agent_action_relative : Agent's most recent passed back rules\n",
        "            agent_last_movement : Agent's most recent successful cardinal action (action which didn't result in bump)\n",
        "            agent_action : Resultant Decrypted Action\n",
        "        '''\n",
        "\n",
        "        self.agent_action_relative = agent.rules()\n",
        "        if self.agent_action_relative != \"suck\" and self.agent_action_relative != \"hose\":\n",
        "            print(\"_____ Interpreting Agent Action _____\")\n",
        "            print(f\"Relative Action: {self.agent_action_relative}\")\n",
        "            print(f\"Interpreted Bearing Action: {self.agent_last_movement}\")\n",
        "            self.agent_action = str(movement_decrypt[self.agent_last_movement][self.agent_action_relative])\n",
        "        else:\n",
        "            self.agent_action = self.agent_action_relative\n",
        "        print(f\"Resultant Action: {self.agent_action}\")\n",
        "\n",
        "    def check_bounds(self, test_position, old_position):\n",
        "        '''\n",
        "        Checks whether the Agent movement will result in a Bump or result in movement.\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            test_position : the proposed position after the agents movement has been applied to current position\n",
        "            old_position : the current agent position\n",
        "\n",
        "        Variables\n",
        "        ---------\n",
        "            agent_last_movement : Agent's most recent successful cardinal action (action which didn't result in bump)\n",
        "\n",
        "        Return\n",
        "        ----------\n",
        "        position : list\n",
        "                The first element represents the y coordinate and the second represents the x coordinate.\n",
        "        '''\n",
        "\n",
        "        print(f\"Test Position: {test_position}\")\n",
        "        if 0 <= test_position[0] < 6 and 0 <= test_position[1] < 7:\n",
        "            if str(self.world[test_position[0]][test_position[1]]) != \"WALL\" and str(self.world[test_position[0]][test_position[1]]) != \"OUT\" and not '[WALL, DIRTY]' in str(self.world[test_position[0]][test_position[1]]):\n",
        "                self.agent_last_movement = self.agent_action\n",
        "                print(f\"Success: Test Position Valid, Returning : {test_position}\")\n",
        "                return test_position\n",
        "            else:\n",
        "                print(f\"Failure: Bumped Into WALL, Returning : {old_position}\")\n",
        "                if \"DIRTY\" in str(self.world[test_position[0]][test_position[1]]) and \"WALL\" in str(self.world[test_position[0]][test_position[1]]):\n",
        "                    print(\"BEEEE BOOOO BEEE BOOO\")\n",
        "                    self.hose_percept = True\n",
        "                self.universal_last_agent_action = self.agent_action\n",
        "                self.bump = True\n",
        "                return old_position\n",
        "        else:\n",
        "            print(f\"Failure: Bumped Into OUT OF BOUNDS, Returning : {old_position}\")\n",
        "            self.bump = True\n",
        "            return old_position\n",
        "\n",
        "class Simple_Vacuum_Environment(Vacuum_Environment):\n",
        "    \"\"\"\n",
        "    A class representing a vacuum environment for the Reflex_Agent with nothing (0), clean (1), wall (2), dirty (3)\n",
        "\n",
        "    Different than normal_vaccuum_enviornment in the way that it\n",
        "    records agent movement to figure out where the agent has rotated to regardless of it's success\n",
        "\n",
        "    Normal vaccuum enviiornment only changes agent headiing if it doesn't bump into anything\n",
        "\n",
        "    ...\n",
        "    Methods\n",
        "    -------\n",
        "    agent_update()\n",
        "        Updates the agent and interprets the agent movement.\n",
        "    check_bounds()\n",
        "        Checks whether the Agent movement will result in a Bump or result in movement.\n",
        "    \"\"\"\n",
        "\n",
        "    def agent_update(self, agent):\n",
        "        '''\n",
        "        Updates the agent and interprets the agent movement.\n",
        "        For info on why we're using relative positioning and directions here, see wiki or agent descriptions.\n",
        "\n",
        "        ----------\n",
        "        Parameters\n",
        "            agent : Agent to be updated and taken action from\n",
        "        ----------\n",
        "        Variables\n",
        "            agent_action_relative : Agent's most recent passed back rules\n",
        "            agent_last_movement : Agent's most recent successful action (action which didn't result in bump)\n",
        "            agent_action : Resultant Decrypted Action\n",
        "        '''\n",
        "        self.agent_action_relative = agent.rules()\n",
        "        if self.agent_action_relative != \"suck\":\n",
        "            print(\"_____ Interpreting Agent Action _____\")\n",
        "            print(f\"Relative Action: {self.agent_action_relative}\")\n",
        "            print(f\"Interpreted Bearing Action: {self.agent_last_movement}\")\n",
        "            self.agent_action = str(movement_decrypt[self.agent_last_movement][self.agent_action_relative])\n",
        "            self.agent_last_movement = self.agent_action\n",
        "        else:\n",
        "            self.agent_action = self.agent_action_relative\n",
        "        print(f\"Resultant Action: {self.agent_action}\")\n",
        "\n",
        "    def check_bounds(self, test_position, old_position):\n",
        "        '''\n",
        "        Checks whether the Agent movement will result in a Bump or result in movement.\n",
        "\n",
        "        ----------\n",
        "        Parameters\n",
        "            test_position : the proposed position after the agents movement has been applied to current position\n",
        "            old_position : the current agent position\n",
        "        ----------\n",
        "        Variables\n",
        "            agent_last_movement : Agent's most recent successful action (action which didn't result in bump)\n",
        "        ----------\n",
        "        Returns\n",
        "            position : [y coordinate, x coordinate]\n",
        "        '''\n",
        "\n",
        "        print(f\"Test Position: {test_position}\")\n",
        "        if 0 <= test_position[0] < 6 and 0 <= test_position[1] < 7:\n",
        "            if str(self.world[test_position[0]][test_position[1]]) != \"WALL\" and str(self.world[test_position[0]][test_position[1]]) != \"OUT\":\n",
        "                self.agent_last_movement = self.agent_action\n",
        "                print(f\"Success: Test Position Valid, Returning : {test_position}\")\n",
        "                return test_position\n",
        "            else:\n",
        "                print(f\"Failure: Bumped Into WALL, Returning : {old_position}\")\n",
        "                self.bump = True\n",
        "                if \"DIRTY\" in str(self.world[test_position[0]][test_position[1]]):\n",
        "                    self.hose_percept = True\n",
        "                else:\n",
        "                    self.hose_percept = False\n",
        "                return old_position\n",
        "        else:\n",
        "            print(f\"Failure: Bumped Into OUT OF BOUNDS, Returning : {old_position}\")\n",
        "            self.bump = True\n",
        "            return old_position\n",
        "\n",
        "class Defective_Vacuum_Environment(Vacuum_Environment):\n",
        "    \"\"\"\n",
        "    A class representing a vacuum environment for the Reflex_Agent with nothing (0), clean (1), wall (2), dirty (3)\n",
        "\n",
        "    Different than normal_vaccuum_enviornment in the way that it\n",
        "    records agent movement to figure out where the agent has rotated to regardless of it's success\n",
        "\n",
        "    Normal vaccuum enviiornment only changes agent headiing if it doesn't bump into anything\n",
        "\n",
        "    ...\n",
        "    Methods\n",
        "    -------\n",
        "    agent_update()\n",
        "        Updates the agent and interprets the agent movement.\n",
        "    check_bounds()\n",
        "        Checks whether the Agent movement will result in a Bump or result in movement.\n",
        "    \"\"\"\n",
        "\n",
        "    def agent_update(self, agent):\n",
        "        '''\n",
        "        Updates the agent and interprets the agent movement.\n",
        "        For info on why we're using relative positioning and directions here, see wiki or agent descriptions.\n",
        "\n",
        "        ----------\n",
        "        Parameters\n",
        "            agent : Agent to be updated and taken action from\n",
        "        ----------\n",
        "        Variables\n",
        "            agent_action_relative : Agent's most recent passed back rules\n",
        "            agent_last_movement : Agent's most recent successful action (action which didn't result in bump)\n",
        "            agent_action : Resultant Decrypted Action\n",
        "        '''\n",
        "        self.agent_action_relative = agent.rules()\n",
        "        if self.agent_action_relative != \"suck\":\n",
        "            print(\"_____ Interpreting Agent Action _____\")\n",
        "            print(f\"Relative Action: {self.agent_action_relative}\")\n",
        "            print(f\"Interpreted Bearing Action: {self.agent_last_movement}\")\n",
        "            self.agent_action = str(movement_decrypt[self.agent_last_movement][self.agent_action_relative])\n",
        "            self.agent_last_movement = self.agent_action\n",
        "        else:\n",
        "            if randint(0, 4) == 1:\n",
        "                self.defective = True\n",
        "            else:\n",
        "                self.defective = False\n",
        "            if randint(0, 4) == 1:\n",
        "                self.leak_dirt = True\n",
        "            else:\n",
        "                self.leak_dirt = False\n",
        "            self.agent_action = self.agent_action_relative\n",
        "        print(f\"Resultant Action: {self.agent_action}\")\n",
        "\n",
        "    def check_bounds(self, test_position, old_position):\n",
        "        '''\n",
        "        Checks whether the Agent movement will result in a Bump or result in movement.\n",
        "\n",
        "        ----------\n",
        "        Parameters\n",
        "            test_position : the proposed position after the agents movement has been applied to current position\n",
        "            old_position : the current agent position\n",
        "        ----------\n",
        "        Variables\n",
        "            agent_last_movement : Agent's most recent successful action (action which didn't result in bump)\n",
        "        ----------\n",
        "        Returns\n",
        "            position : [y coordinate, x coordinate]\n",
        "        '''\n",
        "\n",
        "        print(f\"Test Position: {test_position}\")\n",
        "        if 0 <= test_position[0] < 6 and 0 <= test_position[1] < 7:\n",
        "            if str(self.world[test_position[0]][test_position[1]]) != \"WALL\" and str(self.world[test_position[0]][test_position[1]]) != \"OUT\":\n",
        "                self.agent_last_movement = self.agent_action\n",
        "                print(f\"Success: Test Position Valid, Returning : {test_position}\")\n",
        "                return test_position\n",
        "            else:\n",
        "                print(f\"Failure: Bumped Into WALL, Returning : {old_position}\")\n",
        "                if \"DIRTY\" in str(self.world[test_position[0]][test_position[1]]):\n",
        "                    self.hose_percept = True\n",
        "                else:\n",
        "                    self.hose_percept = False\n",
        "                self.bump = True\n",
        "                return old_position\n",
        "        else:\n",
        "            print(f\"Failure: Bumped Into OUT OF BOUNDS, Returning : {old_position}\")\n",
        "            self.bump = True\n",
        "            return old_position"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize():\n",
        "    '''\n",
        "    A function used to stress test the agents and environments.\n",
        "    '''\n",
        "    value_list = []\n",
        "    for y in range(125):\n",
        "        test_total_score = 0\n",
        "        test_step_max = 1000\n",
        "        test_steps = 0\n",
        "        test_run = True\n",
        "        test_vacuum_world = Normal_Vacuum_Environment()\n",
        "        test_vacuum_world.create_world(meister)\n",
        "        test_roomba = Model_Agent()\n",
        "        while test_run:\n",
        "            if test_steps == test_step_max:\n",
        "                test_run = False\n",
        "            test_vacuum_world.agent_percept(test_roomba)\n",
        "            test_vacuum_world.agent_update(test_roomba)\n",
        "            test_vacuum_world.change_environment()\n",
        "            test_steps += 1\n",
        "        value_list.append(test_vacuum_world.score)\n",
        "    print(value_list[-20:])\n",
        "    print(average(value_list))\n",
        "    print(Counter(value_list))\n",
        "\n",
        "def average(lst):\n",
        "    '''\n",
        "    Gets the average of elements in a list.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    lst : list\n",
        "        The integer list you want to get the average for every element.\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The average of the elements in the list.\n",
        "    '''\n",
        "\n",
        "    return sum(lst) / len(lst)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    '''\n",
        "    The main loop of the program.\n",
        "    Variables\n",
        "    ----------\n",
        "    total_score : into\n",
        "        The number of times the agent has completed the environment (has cleaned the dirty room).\n",
        "    steps_max : int\n",
        "        The number of steps the environment will take to complete the program.\n",
        "    steps : int\n",
        "        Keeps track of the number of steps the environment takes.\n",
        "    run : bool\n",
        "        Keeps track of when the environment is running and when it has stopped.\n",
        "    vacuum_world : Object\n",
        "        An object from the Vacuum_Environment() class\n",
        "    roomba : Object\n",
        "        An object from the Agent() class\n",
        "    '''\n",
        "    out_tile = Tile.out()\n",
        "    clean_tile = Tile.clean()\n",
        "    wall_tile = Tile.wall()\n",
        "    dirty_tile = Tile.dirty()\n",
        "    total_score = 0\n",
        "    step_max = 1000\n",
        "    steps = 0\n",
        "    run = True\n",
        "    vacuum_world = Normal_Vacuum_Environment()\n",
        "    vacuum_world.create_world(depue)\n",
        "    print(f\"Initial State: {vacuum_world}\")\n",
        "    roomba = Toyota_Corolla_Agent_Plus()\n",
        "    while run:\n",
        "        if steps == step_max:\n",
        "            run = False\n",
        "        print(\"-------------------------\")\n",
        "        print(f\"Step # {steps}\")\n",
        "        vacuum_world.agent_percept(roomba)\n",
        "        vacuum_world.agent_update(roomba)\n",
        "        vacuum_world.change_environment()\n",
        "        # vacuum_world.do_kids_create_dirt()\n",
        "        print(\"-    Other Debug Info     -\")\n",
        "        print(f\"World State: \\n{vacuum_world}\")\n",
        "        print(f\"Agent Percept: {roomba.percepts}\")\n",
        "        print(f\"Action: {roomba.action}\")\n",
        "        print(f\"Last Passed Action: {vacuum_world.agent_last_movement}\")\n",
        "        print(f\"Agent Position: {vacuum_world.agent_position}\")\n",
        "        print(f\"Latest Roomba Performance: {roomba.performance}\")\n",
        "        print(f\"Latest World Performance: {vacuum_world.score}\")\n",
        "        steps += 1\n",
        "\n",
        "    total_score += vacuum_world.score\n",
        "    if total_score > 0:\n",
        "        print(f\"\\nThe roomba has completed the task(s) in the environment(s) {total_score} times.\")\n",
        "    else:\n",
        "        print(\"\\nThe roomba has not completed the task(s) in the environment.\")\n",
        "\n",
        "    optimize()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python3"
    },
    "kernelspec": {
      "argv": [
        "G:/Anaconda\\python.exe",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.25.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}